{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c205db6-661f-45c8-92b8-0f6c356264f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate the mock inventory data : first defining categories of items and then defining data set for items with weight and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec26d27-0ef6-4c7d-844b-badb4007c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock data with dimensions generated and saved to 'mock_inventory_data_with_dimensions.csv'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define categories and items\n",
    "categories = {\n",
    "    \"Grocery\": [\"Rice\", \"Wheat\", \"Oil\", \"Sugar\", \"Salt\", \"Cereal\", \"Pasta\"],\n",
    "    \"Chemical\": [\"Detergent\", \"Bleach\", \"Acid\", \"Alkali\"],\n",
    "    \"Inflammable\": [\"Gasoline\", \"Alcohol\", \"Paint\"],\n",
    "    \"Electronics\": [\"Laptop\", \"Mobile\", \"Camera\", \"Headphones\"],\n",
    "    \"Furniture\": [\"Table\", \"Chair\", \"Couch\", \"Bed\"],\n",
    "    \"Clothing\": [\"Shirt\", \"Pants\", \"Jacket\", \"Shoes\"],\n",
    "    \"Stationery\": [\"Pens\", \"Notebooks\", \"Markers\", \"Staplers\"],\n",
    "    \"Books\": [\"Fiction\", \"Non-fiction\", \"Academic\", \"Comics\"],\n",
    "    \"Pharmacy\": [\"Vitamins\", \"Painkillers\", \"Prescription Medicine\"],\n",
    "    \"Toys\": [\"Board Games\", \"Dolls\", \"Puzzles\", \"Action Figures\"],\n",
    "    \"Pet Supplies\": [\"Pet Food\", \"Pet Toys\", \"Pet Beds\", \"Pet Care Products\"],\n",
    "    \"Sports Goods\": [\"Football\", \"Basketball\", \"Tennis Rackets\", \"Golf Clubs\"],\n",
    "    \"Kitchenware\": [\"Pots\", \"Pans\", \"Cutlery\", \"Plates\"],\n",
    "    \"Cosmetics\": [\"Lipstick\", \"Foundation\", \"Mascara\", \"Eyeliner\"],\n",
    "    \"Hardware\": [\"Screws\", \"Nails\", \"Drills\", \"Hammers\"],\n",
    "    \"Garden Supplies\": [\"Seeds\", \"Fertilizer\", \"Gardening Tools\", \"Plant Pots\"],\n",
    "    \"Automotive\": [\"Car Oil\", \"Wipers\", \"Tires\", \"Batteries\"]\n",
    "}\n",
    "\n",
    "# Dataset of items with their dimensions (weight, height, width, depth)\n",
    "items_data = {\n",
    "    \"Rice\": [1.0, 30, 20, 10],\n",
    "    \"Wheat\": [1.0, 30, 20, 10],\n",
    "    \"Oil\": [0.5, 10, 5, 5],\n",
    "    \"Sugar\": [1.0, 30, 20, 10],\n",
    "    \"Salt\": [1.0, 30, 20, 10],\n",
    "    \"Cereal\": [0.5, 25, 15, 5],\n",
    "    \"Pasta\": [0.5, 25, 15, 5],\n",
    "    \"Detergent\": [0.8, 30, 20, 10],\n",
    "    \"Bleach\": [1.0, 30, 20, 10],\n",
    "    \"Acid\": [0.5, 10, 5, 5],\n",
    "    \"Alkali\": [0.5, 10, 5, 5],\n",
    "    \"Gasoline\": [2.0, 40, 30, 20],\n",
    "    \"Alcohol\": [1.0, 30, 20, 10],\n",
    "    \"Paint\": [1.5, 35, 25, 15],\n",
    "    \"Laptop\": [1.5, 40, 30, 5],\n",
    "    \"Mobile\": [0.2, 15, 10, 2],\n",
    "    \"Camera\": [0.3, 20, 15, 10],\n",
    "    \"Headphones\": [0.5, 20, 20, 10],\n",
    "    \"Table\": [20.0, 100, 60, 50],\n",
    "    \"Chair\": [5.0, 50, 50, 50],\n",
    "    \"Couch\": [50.0, 200, 90, 90],\n",
    "    \"Bed\": [30.0, 200, 150, 50],\n",
    "    \"Shirt\": [0.3, 30, 20, 2],\n",
    "    \"Pants\": [0.5, 40, 30, 2],\n",
    "    \"Jacket\": [1.0, 50, 40, 5],\n",
    "    \"Shoes\": [1.0, 30, 20, 10],\n",
    "    \"Pens\": [0.1, 10, 2, 2],\n",
    "    \"Notebooks\": [0.5, 30, 20, 2],\n",
    "    \"Markers\": [0.2, 15, 3, 3],\n",
    "    \"Staplers\": [0.3, 15, 5, 5],\n",
    "    \"Fiction\": [0.5, 25, 15, 5],\n",
    "    \"Non-fiction\": [0.6, 30, 20, 6],\n",
    "    \"Academic\": [1.0, 40, 25, 8],\n",
    "    \"Comics\": [0.4, 25, 15, 4],\n",
    "    \"Vitamins\": [0.1, 10, 5, 5],\n",
    "    \"Painkillers\": [0.1, 10, 5, 5],\n",
    "    \"Prescription Medicine\": [0.2, 15, 10, 5],\n",
    "    \"Board Games\": [1.0, 40, 30, 10],\n",
    "    \"Dolls\": [0.5, 30, 20, 10],\n",
    "    \"Puzzles\": [0.3, 20, 15, 5],\n",
    "    \"Action Figures\": [0.4, 25, 15, 10],\n",
    "    \"Pet Food\": [2.0, 40, 30, 20],\n",
    "    \"Pet Toys\": [0.5, 20, 15, 10],\n",
    "    \"Pet Beds\": [3.0, 60, 50, 20],\n",
    "    \"Pet Care Products\": [0.5, 25, 15, 10],\n",
    "    \"Football\": [0.6, 22, 22, 22],\n",
    "    \"Basketball\": [0.6, 24, 24, 24],\n",
    "    \"Tennis Rackets\": [0.3, 70, 30, 5],\n",
    "    \"Golf Clubs\": [1.5, 100, 15, 15],\n",
    "    \"Pots\": [1.0, 30, 20, 10],\n",
    "    \"Pans\": [1.0, 30, 20, 10],\n",
    "    \"Cutlery\": [0.5, 15, 10, 5],\n",
    "    \"Plates\": [0.8, 20, 20, 5],\n",
    "    \"Lipstick\": [0.05, 10, 2, 2],\n",
    "    \"Foundation\": [0.1, 10, 5, 5],\n",
    "    \"Mascara\": [0.05, 10, 2, 2],\n",
    "    \"Eyeliner\": [0.05, 10, 2, 2],\n",
    "    \"Screws\": [0.1, 10, 5, 5],\n",
    "    \"Nails\": [0.1, 10, 5, 5],\n",
    "    \"Drills\": [2.0, 30, 20, 10],\n",
    "    \"Hammers\": [1.5, 25, 10, 5],\n",
    "    \"Seeds\": [0.5, 15, 10, 5],\n",
    "    \"Fertilizer\": [2.0, 30, 20, 10],\n",
    "    \"Gardening Tools\": [1.0, 50, 20, 10],\n",
    "    \"Plant Pots\": [0.5, 30, 20, 20],\n",
    "    \"Car Oil\": [5.0, 40, 30, 20],\n",
    "    \"Wipers\": [0.5, 70, 10, 5],\n",
    "    \"Tires\": [10.0, 70, 70, 20],\n",
    "    \"Batteries\": [2.0, 30, 20, 10]\n",
    "}\n",
    "\n",
    "# Generate mock data for items\n",
    "num_items = 100000\n",
    "items = []\n",
    "\n",
    "# Define realistic distributions for sizes (cubic meters) and weights (kg)\n",
    "size_distribution = {\n",
    "    \"Grocery\": (0.01, 0.1),\n",
    "    \"Chemical\": (0.05, 0.5),\n",
    "    \"Inflammable\": (0.1, 1.0),\n",
    "    \"Electronics\": (0.02, 0.5),\n",
    "    \"Furniture\": (0.5, 5.0),\n",
    "    \"Clothing\": (0.01, 0.2),\n",
    "    \"Stationery\": (0.01, 0.1),\n",
    "    \"Books\": (0.01, 0.2),\n",
    "    \"Pharmacy\": (0.01, 0.1),\n",
    "    \"Toys\": (0.01, 0.5),\n",
    "    \"Pet Supplies\": (0.1, 1.0),\n",
    "    \"Sports Goods\": (0.1, 2.0),\n",
    "    \"Kitchenware\": (0.01, 0.5),\n",
    "    \"Cosmetics\": (0.01, 0.1),\n",
    "    \"Hardware\": (0.01, 1.0),\n",
    "    \"Garden Supplies\": (0.01, 2.0),\n",
    "    \"Automotive\": (0.1, 5.0)\n",
    "}\n",
    "\n",
    "weight_distribution = {\n",
    "    \"Grocery\": (0.1, 5),\n",
    "    \"Chemical\": (0.5, 10),\n",
    "    \"Inflammable\": (0.5, 20),\n",
    "    \"Electronics\": (0.2, 3),\n",
    "    \"Furniture\": (5, 50),\n",
    "    \"Clothing\": (0.1, 2),\n",
    "    \"Stationery\": (0.01, 0.5),\n",
    "    \"Books\": (0.1, 1.0),\n",
    "    \"Pharmacy\": (0.01, 0.5),\n",
    "    \"Toys\": (0.1, 2.0),\n",
    "    \"Pet Supplies\": (0.5, 5.0),\n",
    "    \"Sports Goods\": (0.2, 5.0),\n",
    "    \"Kitchenware\": (0.1, 3.0),\n",
    "    \"Cosmetics\": (0.01, 0.5),\n",
    "    \"Hardware\": (0.1, 5.0),\n",
    "    \"Garden Supplies\": (0.1, 5.0),\n",
    "    \"Automotive\": (0.5, 10.0)\n",
    "}\n",
    "\n",
    "\n",
    "#randomly assigining the items from the defined values above so that\n",
    "# a database can be created\n",
    "\n",
    "for _ in range(num_items):\n",
    "    category = random.choice(list(categories.keys()))\n",
    "    item_name = random.choice(categories[category])\n",
    "    size = round(random.uniform(*size_distribution[category]), 2)\n",
    "    weight = round(random.uniform(*weight_distribution[category]), 2)\n",
    "    tags = [category]\n",
    "\n",
    "    # Retrieve dimensions from items_data\n",
    "    dimensions = items_data[item_name]\n",
    "    height, width, depth = dimensions[1], dimensions[2], dimensions[3]\n",
    "\n",
    "\n",
    "\n",
    "    items.append({\n",
    "        \"ItemName\": item_name,\n",
    "        \"Category\": category,\n",
    "        \"Size(m^3)\": size,\n",
    "        \"Weight(kg)\": weight,\n",
    "        \"Height(cm)\": height,\n",
    "        \"Width(cm)\": width,\n",
    "        \"Depth(cm)\": depth,\n",
    "        \"Tags\": \", \".join(tags),\n",
    "\n",
    "    })\n",
    "\n",
    "# Create DataFrame(panda library structured data) and save to CSV\n",
    "df = pd.DataFrame(items)\n",
    "df.to_csv(\"mock_inventory_data_with_dimensions.csv\", index=False)\n",
    "\n",
    "print(\"Mock data with dimensions generated and saved to 'mock_inventory_data_with_dimensions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d4aaaa-d128-428a-aa04-13ab321da84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock transaction data generated and saved to 'mock_transaction_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define categories and items\n",
    "categories = {\n",
    "    \"Grocery\": [\"Rice\", \"Wheat\", \"Oil\", \"Sugar\", \"Salt\", \"Cereal\", \"Pasta\"],\n",
    "    \"Chemical\": [\"Detergent\", \"Bleach\", \"Acid\", \"Alkali\"],\n",
    "    \"Inflammable\": [\"Gasoline\", \"Alcohol\", \"Paint\"],\n",
    "    \"Electronics\": [\"Laptop\", \"Mobile\", \"Camera\", \"Headphones\"],\n",
    "    \"Furniture\": [\"Table\", \"Chair\", \"Couch\", \"Bed\"],\n",
    "    \"Clothing\": [\"Shirt\", \"Pants\", \"Jacket\", \"Shoes\"],\n",
    "    \"Stationery\": [\"Pens\", \"Notebooks\", \"Markers\", \"Staplers\"],\n",
    "    \"Books\": [\"Fiction\", \"Non-fiction\", \"Academic\", \"Comics\"],\n",
    "    \"Pharmacy\": [\"Vitamins\", \"Painkillers\", \"Prescription Medicine\"],\n",
    "    \"Toys\": [\"Board Games\", \"Dolls\", \"Puzzles\", \"Action Figures\"],\n",
    "    \"Pet Supplies\": [\"Pet Food\", \"Pet Toys\", \"Pet Beds\", \"Pet Care Products\"],\n",
    "    \"Sports Goods\": [\"Football\", \"Basketball\", \"Tennis Rackets\", \"Golf Clubs\"],\n",
    "    \"Kitchenware\": [\"Pots\", \"Pans\", \"Cutlery\", \"Plates\"],\n",
    "    \"Cosmetics\": [\"Lipstick\", \"Foundation\", \"Mascara\", \"Eyeliner\"],\n",
    "    \"Hardware\": [\"Screws\", \"Nails\", \"Drills\", \"Hammers\"],\n",
    "    \"Garden Supplies\": [\"Seeds\", \"Fertilizer\", \"Gardening Tools\", \"Plant Pots\"],\n",
    "    \"Automotive\": [\"Car Oil\", \"Wipers\", \"Tires\", \"Batteries\"]\n",
    "}\n",
    "\n",
    "# Generate mock data for transactions\n",
    "num_transactions = 10000\n",
    "max_items_per_transaction = 10\n",
    "\n",
    "transactions = []\n",
    "\n",
    "\n",
    "for _ in range(num_transactions):\n",
    "    transaction = []\n",
    "    num_items = random.randint(1, max_items_per_transaction) #random int will be genereted b/w 1 to maxitemtrans\n",
    "\n",
    "    for _ in range(num_items):\n",
    "        category = random.choice(list(categories.keys()))\n",
    "        item_name = random.choice(categories[category])\n",
    "        transaction.append(item_name)\n",
    "\n",
    "    transactions.append(transaction)\n",
    "\n",
    "# Create a DataFrame where each row is a transaction\n",
    "transaction_df = pd.DataFrame(transactions)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "transaction_df.to_csv(\"mock_transaction_data.csv\", index=False, header=False)\n",
    "\n",
    "print(\"Mock transaction data generated and saved to 'mock_transaction_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc8a60-91db-4401-8a7b-63a971813cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlxtend  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066ec99c-6b13-4161-ba26-087e919ea24f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './mock_transaction_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrequent_patterns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fpgrowth, association_rules\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./mock_transaction_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Transform the dataset\u001b[39;00m\n\u001b[1;32m      9\u001b[0m te \u001b[38;5;241m=\u001b[39m TransactionEncoder()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mock_transaction_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('./mock_transaction_data.csv', header=None)\n",
    "\n",
    "# Transform the dataset\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Display the transformed dataset. #the items under which transaction happend is true otherwise false\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ca3a07-2711-4a07-8516-6150d4180707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock transaction data generated and saved to 'mock_transaction_data.csv'\n",
      "Transformed Dataset:\n",
      "   Academic   Acid  Action Figures  Alcohol  Alkali  Basketball  Batteries  \\\n",
      "0     False  False           False    False    True       False      False   \n",
      "1     False   True           False    False    True       False      False   \n",
      "2     False  False           False    False   False       False      False   \n",
      "3     False  False           False     True   False       False      False   \n",
      "4     False  False           False    False   False       False      False   \n",
      "\n",
      "     Bed  Bleach  Board Games  ...  Shirt  Shoes  Staplers  Sugar  Table  \\\n",
      "0  False   False        False  ...  False  False     False  False  False   \n",
      "1  False   False        False  ...  False  False     False  False  False   \n",
      "2  False   False        False  ...  False  False     False  False  False   \n",
      "3  False   False         True  ...   True  False      True  False  False   \n",
      "4  False   False        False  ...  False  False     False   True  False   \n",
      "\n",
      "   Tennis Rackets  Tires  Vitamins  Wheat  Wipers  \n",
      "0           False  False     False   True   False  \n",
      "1           False  False     False  False   False  \n",
      "2           False  False      True  False   False  \n",
      "3           False  False     False  False   False  \n",
      "4           False  False     False  False   False  \n",
      "\n",
      "[5 rows x 69 columns]\n",
      "Frequent Itemsets:\n",
      "   support      itemsets\n",
      "0   0.1889       (Wheat)\n",
      "1   0.1379  (Headphones)\n",
      "2   0.0719      (Alkali)\n",
      "3   0.0718      (Plates)\n",
      "4   0.0390  (Plant Pots)\n",
      "Association Rules:\n",
      "     antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0        (Wheat)      (Rice)              0.1889              0.1934   0.0397   \n",
      "1         (Rice)     (Wheat)              0.1934              0.1889   0.0397   \n",
      "2        (Wheat)    (Cereal)              0.1889              0.1920   0.0392   \n",
      "3       (Cereal)     (Wheat)              0.1920              0.1889   0.0392   \n",
      "4  (Wheat, Rice)    (Cereal)              0.0397              0.1920   0.0086   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0    0.210164  1.086681  0.003167    1.021225       0.098344  \n",
      "1    0.205274  1.086681  0.003167    1.020603       0.098893  \n",
      "2    0.207517  1.080819  0.002931    1.019580       0.092190  \n",
      "3    0.204167  1.080819  0.002931    1.019183       0.092544  \n",
      "4    0.216625  1.128254  0.000978    1.031434       0.118374  \n",
      "\n",
      "Individual Item Frequencies:\n",
      "    support      itemsets\n",
      "28   0.1934        (Rice)\n",
      "5    0.1920      (Cereal)\n",
      "18   0.1908       (Sugar)\n",
      "0    0.1889       (Wheat)\n",
      "57   0.1879         (Oil)\n",
      "..      ...           ...\n",
      "32   0.0348       (Nails)\n",
      "51   0.0347  (Fertilizer)\n",
      "59   0.0342       (Tires)\n",
      "65   0.0341       (Couch)\n",
      "43   0.0340       (Table)\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "\n",
    "\n",
    "# Define categories and items\n",
    "categories = {\n",
    "    \"Grocery\": [\"Rice\", \"Wheat\", \"Oil\", \"Sugar\", \"Salt\", \"Cereal\", \"Pasta\"],\n",
    "    \"Chemical\": [\"Detergent\", \"Bleach\", \"Acid\", \"Alkali\"],\n",
    "    \"Inflammable\": [\"Gasoline\", \"Alcohol\", \"Paint\"],\n",
    "    \"Electronics\": [\"Laptop\", \"Mobile\", \"Camera\", \"Headphones\"],\n",
    "    \"Furniture\": [\"Table\", \"Chair\", \"Couch\", \"Bed\"],\n",
    "    \"Clothing\": [\"Shirt\", \"Pants\", \"Jacket\", \"Shoes\"],\n",
    "    \"Stationery\": [\"Pens\", \"Notebooks\", \"Markers\", \"Staplers\"],\n",
    "    \"Books\": [\"Fiction\", \"Non-fiction\", \"Academic\", \"Comics\"],\n",
    "    \"Pharmacy\": [\"Vitamins\", \"Painkillers\", \"Prescription Medicine\"],\n",
    "    \"Toys\": [\"Board Games\", \"Dolls\", \"Puzzles\", \"Action Figures\"],\n",
    "    \"Pet Supplies\": [\"Pet Food\", \"Pet Toys\", \"Pet Beds\", \"Pet Care Products\"],\n",
    "    \"Sports Goods\": [\"Football\", \"Basketball\", \"Tennis Rackets\", \"Golf Clubs\"],\n",
    "    \"Kitchenware\": [\"Pots\", \"Pans\", \"Cutlery\", \"Plates\"],\n",
    "    \"Cosmetics\": [\"Lipstick\", \"Foundation\", \"Mascara\", \"Eyeliner\"],\n",
    "    \"Hardware\": [\"Screws\", \"Nails\", \"Drills\", \"Hammers\"],\n",
    "    \"Garden Supplies\": [\"Seeds\", \"Fertilizer\", \"Gardening Tools\", \"Plant Pots\"],\n",
    "    \"Automotive\": [\"Car Oil\", \"Wipers\", \"Tires\", \"Batteries\"]\n",
    "}\n",
    "\n",
    "# Define item purchase probabilities (higher means more likely to be bought together)\n",
    "item_probabilities = {\n",
    "    \"Grocery\": 0.5,\n",
    "    \"Chemical\": 0.1,\n",
    "    \"Inflammable\": 0.05,\n",
    "    \"Electronics\": 0.2,\n",
    "    \"Furniture\": 0.05,\n",
    "    \"Clothing\": 0.1,\n",
    "    \"Stationery\": 0.1,\n",
    "    \"Books\": 0.1,\n",
    "    \"Pharmacy\": 0.1,\n",
    "    \"Toys\": 0.1,\n",
    "    \"Pet Supplies\": 0.05,\n",
    "    \"Sports Goods\": 0.1,\n",
    "    \"Kitchenware\": 0.1,\n",
    "    \"Cosmetics\": 0.05,\n",
    "    \"Hardware\": 0.05,\n",
    "    \"Garden Supplies\": 0.05,\n",
    "    \"Automotive\": 0.05\n",
    "}\n",
    "\n",
    "# Generate mock data for transactions\n",
    "num_transactions = 10000\n",
    "max_items_per_transaction = 10\n",
    "\n",
    "transactions = []\n",
    "\n",
    "for _ in range(num_transactions):\n",
    "    transaction = []\n",
    "    num_items = random.randint(1, max_items_per_transaction)\n",
    "    selected_categories = random.choices(list(categories.keys()), weights=item_probabilities.values(), k=num_items)\n",
    "\n",
    "    for category in selected_categories:\n",
    "        item_name = random.choice(categories[category])\n",
    "        transaction.append(item_name)\n",
    "\n",
    "    transactions.append(transaction)\n",
    "\n",
    "# Create a DataFrame where each row is a transaction\n",
    "transaction_df = pd.DataFrame(transactions)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "transaction_df.to_csv(\"mock_transaction_data.csv\", index=False, header=False)\n",
    "\n",
    "print(\"Mock transaction data generated and saved to 'mock_transaction_data.csv'\")\n",
    "\n",
    "# Transform the dataset\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Display the transformed dataset\n",
    "print(\"Transformed Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Generate frequent itemsets using FP-Growth compare support val with min_support_val\n",
    "min_support_value = 0.005  # Adjusted min_support for more frequent itemsets\n",
    "frequent_itemsets_fp = fpgrowth(df, min_support=min_support_value, use_colnames=True)\n",
    "\n",
    "# Check if frequent itemsets are generated\n",
    "if frequent_itemsets_fp.empty:\n",
    "    print(\"No frequent itemsets found.\")\n",
    "else:\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    print(frequent_itemsets_fp.head())\n",
    "\n",
    "# Generate association rules\n",
    "min_confidence_value = 0.2  # Adjusted min_threshold for confidence\n",
    "if not frequent_itemsets_fp.empty:\n",
    "    rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=min_confidence_value)\n",
    "    if rules_fp.empty:\n",
    "        print(\"No association rules generated.\")\n",
    "    else:\n",
    "        print(\"Association Rules:\")\n",
    "        print(rules_fp.head())\n",
    "else:\n",
    "    print(\"No association rules generated.\")\n",
    "\n",
    "# Sort frequent itemsets by support in descending order\n",
    "sorted_frequent_itemsets = frequent_itemsets_fp.sort_values(by='support', ascending=False)\n",
    "\n",
    "# Extract and display individual item frequencies\n",
    "item_support = sorted_frequent_itemsets[sorted_frequent_itemsets['itemsets'].apply(lambda x: len(x) == 1)]\n",
    "\n",
    "print(\"\\nIndividual Item Frequencies:\")\n",
    "print(item_support)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa4a24e-5d49-4950-a62e-84557133189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted frequent itemsets saved to 'sorted_frequent_itemsets.csv'\n",
      "Individual item frequencies saved to 'individual_item_frequencies.csv'\n",
      "\n",
      "Group Item Frequencies (first 5 rows):\n",
      "    support  itemsets\n",
      "28   0.1934    (Rice)\n",
      "5    0.1920  (Cereal)\n",
      "18   0.1908   (Sugar)\n",
      "0    0.1889   (Wheat)\n",
      "57   0.1879     (Oil)\n",
      "\n",
      "Individual Item Frequencies (first 5 rows):\n",
      "    support  itemsets\n",
      "28   0.1934    (Rice)\n",
      "5    0.1920  (Cereal)\n",
      "18   0.1908   (Sugar)\n",
      "0    0.1889   (Wheat)\n",
      "57   0.1879     (Oil)\n"
     ]
    }
   ],
   "source": [
    "# Sort frequent itemsets by support in descending order\n",
    "sorted_frequent_itemsets = frequent_itemsets_fp.sort_values(by='support', ascending=False)\n",
    "\n",
    "# Extract individual item frequencies\n",
    "item_support = sorted_frequent_itemsets[sorted_frequent_itemsets['itemsets'].apply(lambda x: len(x) == 1)]\n",
    "\n",
    "# Save sorted frequent itemsets to CSV\n",
    "sorted_frequent_itemsets.to_csv('sorted_frequent_itemsets.csv', index=False)\n",
    "print(\"Sorted frequent itemsets saved to 'sorted_frequent_itemsets.csv'\")\n",
    "\n",
    "# Save individual item frequencies to CSV\n",
    "item_support.to_csv('individual_item_frequencies.csv', index=False)\n",
    "print(\"Individual item frequencies saved to 'individual_item_frequencies.csv'\")\n",
    "\n",
    "# Print summaries\n",
    "print(\"\\nGroup Item Frequencies (first 5 rows):\")\n",
    "print(sorted_frequent_itemsets.head())\n",
    "\n",
    "print(\"\\nIndividual Item Frequencies (first 5 rows):\")\n",
    "print(item_support.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e2c99a-e0dc-429b-a8a7-52c4b31ea1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "# Function to generate a warehouse with zones, racks, and slots\n",
    "def generate_warehouse(num_zones):\n",
    "    warehouse = {\"zones\": {}}\n",
    "    for zone_num in range(1, num_zones + 1):\n",
    "        zone_name = f\"Zone {zone_num}\"\n",
    "        warehouse[\"zones\"][zone_name] = {\"racks\": []}\n",
    "        for rack_num in range(1, random.randint(2, 4) + 1):  # Random number of racks per zone\n",
    "            rack_name = f\"Rack {rack_num}\"\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"].append({\"rack_id\": rack_name, \"slots\": []})\n",
    "            for slot_num in range(1, random.randint(2, 3) + 1):  # Random number of slots per rack\n",
    "                slot_name = f\"Slot {slot_num}\"\n",
    "                warehouse[\"zones\"][zone_name][\"racks\"][-1][\"slots\"].append({\n",
    "                    \"slot_id\": slot_name,\n",
    "                    \"max_weight\": random.randint(300, 3000),  # Random max weight\n",
    "                    \"dimensions\": [\n",
    "                        random.randint(30, 80),  # Random dimensions\n",
    "                        random.randint(30, 80),\n",
    "                        random.randint(30, 80)\n",
    "                    ]\n",
    "                })\n",
    "            # Randomly assign near_picking_zone, near_packing_machine, and near_outbound_gate\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_picking_zone\"] = random.choice([True, False])\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_packing_machine\"] = random.choice([True, False])\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_outbound_gate\"] = random.choice([True, False])\n",
    "    return warehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e83622d6-619d-4748-9239-520a51da660c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned slots saved to 'assigned_slots.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Load the mock inventory data\n",
    "df = pd.read_csv(\"mock_inventory_data_with_dimensions.csv\")\n",
    "\n",
    "# Assuming 'item_support' is defined earlier and contains the priority items identified using the FP Growth algorithm\n",
    "priority_items = set(item_support['itemsets'].apply(lambda x: list(x)[0]))\n",
    "\n",
    "# Function to generate a warehouse with zones, racks, and slots\n",
    "def generate_warehouse(num_zones):\n",
    "    warehouse = {\"zones\": {}}\n",
    "    for zone_num in range(1, num_zones + 1):\n",
    "        zone_name = f\"Zone {zone_num}\"\n",
    "        warehouse[\"zones\"][zone_name] = {\"racks\": []}\n",
    "        for rack_num in range(1, random.randint(2, 4) + 1):  # Random number of racks per zone\n",
    "            rack_name = f\"Rack {rack_num}\"\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"].append({\"rack_id\": rack_name, \"slots\": []})\n",
    "            for slot_num in range(1, random.randint(2, 3) + 1):  # Random number of slots per rack\n",
    "                slot_name = f\"Slot {slot_num}\"\n",
    "                warehouse[\"zones\"][zone_name][\"racks\"][-1][\"slots\"].append({\n",
    "                    \"slot_id\": slot_name,\n",
    "                    \"max_weight\": random.randint(300, 3000),  # Random max weight\n",
    "                    \"dimensions\": [\n",
    "                        random.randint(30, 80),  # Random dimensions\n",
    "                        random.randint(30, 80),\n",
    "                        random.randint(30, 80)\n",
    "                    ]\n",
    "                })\n",
    "            # Randomly assign near_picking_zone, near_packing_machine, and near_outbound_gate\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_picking_zone\"] = random.choice([True, False])\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_packing_machine\"] = random.choice([True, False])\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_outbound_gate\"] = random.choice([True, False])\n",
    "    return warehouse\n",
    "\n",
    "# Generate a warehouse with 20 zones\n",
    "warehouse = generate_warehouse(20)\n",
    "\n",
    "# Function to find nearest slot based on item dimensions\n",
    "def find_nearest_slot(item, slots):\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(slots)\n",
    "    distances, indices = nbrs.kneighbors([item])\n",
    "    return indices[0][0]\n",
    "\n",
    "# Function to check if adding item exceeds rack weight limit\n",
    "def can_add_to_rack(current_weight, item_weight, max_weight):\n",
    "    return current_weight + item_weight <= max_weight\n",
    "\n",
    "# Function to assign items to racks and slots using knapsack algorithm\n",
    "def assign_items_to_slots(items, warehouse):\n",
    "    assigned_slots = []\n",
    "    remaining_items = []\n",
    "\n",
    "    for zone, data in warehouse['zones'].items():\n",
    "        for rack in data['racks']:\n",
    "            current_weight = 0\n",
    "\n",
    "            # Separate items into priority and non-priority\n",
    "            priority_items_df = items[items['ItemName'].isin(priority_items)]\n",
    "            non_priority_items_df = items[~items['ItemName'].isin(priority_items)]\n",
    "\n",
    "            # Helper function to allocate items to slots\n",
    "            def allocate_items(item_list):\n",
    "                nonlocal current_weight\n",
    "                for _, item in item_list.iterrows():\n",
    "                    item_name = item['ItemName']\n",
    "                    item_dimensions = [item['Height(cm)'], item['Width(cm)'], item['Depth(cm)']]\n",
    "                    item_weight = item['Weight(kg)']\n",
    "                    item_category = item['Category']\n",
    "\n",
    "                    # Find suitable slots in the current rack\n",
    "                    suitable_slots = []\n",
    "                    for slot in rack['slots']:\n",
    "                        if item_weight <= slot['max_weight'] and all([item_dimensions[i] <= slot['dimensions'][i] for i in range(3)]):\n",
    "                            suitable_slots.append((zone, rack['rack_id'], slot['slot_id'], slot['dimensions'], slot['max_weight'], rack['near_picking_zone'], rack['near_packing_machine'], rack['near_outbound_gate']))\n",
    "\n",
    "                    # Find the nearest slot based on dimensions\n",
    "                    if suitable_slots:\n",
    "                        slot_dimensions = [s[3] for s in suitable_slots]\n",
    "                        nearest_slot_index = find_nearest_slot(item_dimensions, slot_dimensions)\n",
    "\n",
    "                        # Check if adding the item exceeds the rack's weight limit\n",
    "                        if can_add_to_rack(current_weight, item_weight, suitable_slots[nearest_slot_index][4]):\n",
    "                            assigned_slots.append((item_name, suitable_slots[nearest_slot_index]))\n",
    "                            current_weight += item_weight\n",
    "                        else:\n",
    "                            remaining_items.append(item)\n",
    "                    else:\n",
    "                        remaining_items.append(item)\n",
    "\n",
    "            # Allocate priority items first\n",
    "            allocate_items(priority_items_df)\n",
    "            # Allocate non-priority items next\n",
    "            allocate_items(non_priority_items_df)\n",
    "\n",
    "    return assigned_slots, remaining_items\n",
    "\n",
    "# Assign items to slots\n",
    "assigned_slots, remaining_items = assign_items_to_slots(df, warehouse)\n",
    "\n",
    "# Save assigned slots to CSV\n",
    "assigned_slots_df = pd.DataFrame(assigned_slots, columns=['ItemName', 'Assigned Slot'])\n",
    "assigned_slots_df[['Zone', 'Rack', 'Slot', 'Slot Dimensions', 'Max Weight', 'Near Picking Zone', 'Near Packing Machine', 'Near Outbound Gate']] = pd.DataFrame(assigned_slots_df['Assigned Slot'].tolist(), index=assigned_slots_df.index)\n",
    "assigned_slots_df.drop(columns=['Assigned Slot'], inplace=True)\n",
    "assigned_slots_df.to_csv('assigned_slots.csv', index=False)\n",
    "\n",
    "print(\"Assigned slots saved to 'assigned_slots.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ccd5c-5400-42fe-ad63-998f4b1621c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "# New function to check warehouse capacity\n",
    "def check_warehouse_capacity(warehouse, required_capacity=100000):\n",
    "    total_slots = sum(len(rack['slots']) for zone in warehouse['zones'].values() for rack in zone['racks'])\n",
    "    if total_slots >= required_capacity:\n",
    "        print(f\"Warehouse capacity check: PASSED. Total slots: {total_slots}\")\n",
    "    else:\n",
    "        print(f\"Warehouse capacity check: FAILED. Total slots: {total_slots}, Required: {required_capacity}\")\n",
    "    return total_slots >= required_capacity\n",
    "\n",
    "# Modified assign_items_to_slots function\n",
    "def assign_items_to_slots(items, warehouse, sorted_frequent_itemsets):\n",
    "    assigned_slots = []\n",
    "    remaining_items = []\n",
    "    \n",
    "    # Create a dictionary to store items that are frequently sold together\n",
    "    item_groups = {}\n",
    "    for _, row in sorted_frequent_itemsets.iterrows():\n",
    "        if len(row['itemsets']) > 1:\n",
    "            for item in row['itemsets']:\n",
    "                if item not in item_groups:\n",
    "                    item_groups[item] = set()\n",
    "                item_groups[item].update(row['itemsets'])\n",
    "\n",
    "    for zone, data in warehouse['zones'].items():\n",
    "        for rack in data['racks']:\n",
    "            current_weight = 0\n",
    "\n",
    "            # Separate items into priority and non-priority\n",
    "            priority_items_df = items[items['ItemName'].isin(priority_items)]\n",
    "            non_priority_items_df = items[~items['ItemName'].isin(priority_items)]\n",
    "\n",
    "            # Helper function to allocate items to slots\n",
    "            def allocate_items(item_list):\n",
    "                nonlocal current_weight\n",
    "                for _, item in item_list.iterrows():\n",
    "                    item_name = item['ItemName']\n",
    "                    item_dimensions = [item['Height(cm)'], item['Width(cm)'], item['Depth(cm)']]\n",
    "                    item_weight = item['Weight(kg)']\n",
    "                    item_category = item['Category']\n",
    "\n",
    "                    # Find suitable slots in the current rack\n",
    "                    suitable_slots = []\n",
    "                    for slot in rack['slots']:\n",
    "                        if item_weight <= slot['max_weight'] and all([item_dimensions[i] <= slot['dimensions'][i] for i in range(3)]):\n",
    "                            suitable_slots.append((zone, rack['rack_id'], slot['slot_id'], slot['dimensions'], slot['max_weight'], rack['near_picking_zone'], rack['near_packing_machine'], rack['near_outbound_gate']))\n",
    "\n",
    "                    # Find the nearest slot based on dimensions\n",
    "                    if suitable_slots:\n",
    "                        slot_dimensions = [s[3] for s in suitable_slots]\n",
    "                        nearest_slot_index = find_nearest_slot(item_dimensions, slot_dimensions)\n",
    "\n",
    "                        # Prioritize slots near picking zones for priority items\n",
    "                        if item_name in priority_items:\n",
    "                            near_picking_slots = [i for i, s in enumerate(suitable_slots) if s[5]]  # s[5] is near_picking_zone\n",
    "                            if near_picking_slots:\n",
    "                                nearest_slot_index = near_picking_slots[0]\n",
    "\n",
    "                        # Check if adding the item exceeds the rack's weight limit\n",
    "                        if can_add_to_rack(current_weight, item_weight, suitable_slots[nearest_slot_index][4]):\n",
    "                            assigned_slots.append((item_name, suitable_slots[nearest_slot_index]))\n",
    "                            current_weight += item_weight\n",
    "                            \n",
    "                            # Try to allocate frequently sold together items\n",
    "                            if item_name in item_groups:\n",
    "                                for related_item in item_groups[item_name]:\n",
    "                                    related_item_data = items[items['ItemName'] == related_item].iloc[0]\n",
    "                                    if can_add_to_rack(current_weight, related_item_data['Weight(kg)'], suitable_slots[nearest_slot_index][4]):\n",
    "                                        assigned_slots.append((related_item, suitable_slots[nearest_slot_index]))\n",
    "                                        current_weight += related_item_data['Weight(kg)']\n",
    "                                        items = items[items['ItemName'] != related_item]\n",
    "                        else:\n",
    "                            remaining_items.append(item)\n",
    "                    else:\n",
    "                        remaining_items.append(item)\n",
    "\n",
    "            # Allocate priority items first\n",
    "            allocate_items(priority_items_df)\n",
    "            # Allocate non-priority items next\n",
    "            allocate_items(non_priority_items_df)\n",
    "\n",
    "    return assigned_slots, remaining_items\n",
    "\n",
    "# Generate warehouse and check capacity\n",
    "warehouse = generate_warehouse(20)\n",
    "if not check_warehouse_capacity(warehouse):\n",
    "    print(\"Warning: Warehouse may not have sufficient capacity for 100,000 items.\")\n",
    "\n",
    "# Assign items to slots\n",
    "assigned_slots, remaining_items = assign_items_to_slots(df, warehouse, sorted_frequent_itemsets)\n",
    "\n",
    "# Save assigned slots to CSV with priority and near picking zone labels\n",
    "assigned_slots_df = pd.DataFrame(assigned_slots, columns=['ItemName', 'Assigned Slot'])\n",
    "assigned_slots_df[['Zone', 'Rack', 'Slot', 'Slot Dimensions', 'Max Weight', 'Near Picking Zone', 'Near Packing Machine', 'Near Outbound Gate']] = pd.DataFrame(assigned_slots_df['Assigned Slot'].tolist(), index=assigned_slots_df.index)\n",
    "assigned_slots_df['Is Priority Item'] = assigned_slots_df['ItemName'].isin(priority_items)\n",
    "assigned_slots_df['Is Near Picking Zone'] = assigned_slots_df['Near Picking Zone']\n",
    "assigned_slots_df['Priority Near Picking'] = assigned_slots_df['Is Priority Item'] & assigned_slots_df['Is Near Picking Zone']\n",
    "assigned_slots_df.drop(columns=['Assigned Slot'], inplace=True)\n",
    "assigned_slots_df.to_csv('assigned_slots.csv', index=False)\n",
    "\n",
    "print(\"Assigned slots saved to 'assigned_slots.csv'.\")\n",
    "print(f\"Number of items successfully assigned: {len(assigned_slots)}\")\n",
    "print(f\"Number of items not assigned: {len(remaining_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f55df2-ad83-4af7-94e9-237d0c23f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_warehouse_details(warehouse):\n",
    "    details = []\n",
    "    for zone_name, zone_data in warehouse['zones'].items():\n",
    "        for rack in zone_data['racks']:\n",
    "            rack_id = rack['rack_id']\n",
    "            near_picking = rack['near_picking_zone']\n",
    "            near_packing = rack['near_packing_machine']\n",
    "            near_outbound = rack['near_outbound_gate']\n",
    "            for slot in rack['slots']:\n",
    "                slot_id = slot['slot_id']\n",
    "                max_weight = slot['max_weight']\n",
    "                dimensions = slot['dimensions']\n",
    "                details.append({\n",
    "                    'Zone': zone_name,\n",
    "                    'Rack': rack_id,\n",
    "                    'Slot': slot_id,\n",
    "                    'Max Weight': max_weight,\n",
    "                    'Dimensions': dimensions,\n",
    "                    'Near Picking Zone': near_picking,\n",
    "                    'Near Packing Machine': near_packing,\n",
    "                    'Near Outbound Gate': near_outbound\n",
    "                })\n",
    "    return pd.DataFrame(details)\n",
    "\n",
    "def get_items_per_slot(assigned_slots_df):\n",
    "    items_per_slot = defaultdict(list)\n",
    "    for _, row in assigned_slots_df.iterrows():\n",
    "        slot_key = (row['Zone'], row['Rack'], row['Slot'])\n",
    "        items_per_slot[slot_key].append(row['ItemName'])\n",
    "    \n",
    "    slot_contents = []\n",
    "    for (zone, rack, slot), items in items_per_slot.items():\n",
    "        slot_contents.append({\n",
    "            'Zone': zone,\n",
    "            'Rack': rack,\n",
    "            'Slot': slot,\n",
    "            'Items': ', '.join(items),\n",
    "            'Item Count': len(items)\n",
    "        })\n",
    "    return pd.DataFrame(slot_contents)\n",
    "\n",
    "# After generating the warehouse and assigning items\n",
    "warehouse_details = get_warehouse_details(warehouse)\n",
    "warehouse_details.to_csv('warehouse_details.csv', index=False)\n",
    "print(\"Warehouse details saved to 'warehouse_details.csv'\")\n",
    "\n",
    "# After assigning items to slots\n",
    "items_per_slot = get_items_per_slot(assigned_slots_df)\n",
    "items_per_slot.to_csv('items_per_slot.csv', index=False)\n",
    "print(\"Items per slot saved to 'items_per_slot.csv'\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nWarehouse Summary:\")\n",
    "print(f\"Total Zones: {warehouse_details['Zone'].nunique()}\")\n",
    "print(f\"Total Racks: {warehouse_details['Rack'].nunique()}\")\n",
    "print(f\"Total Slots: {len(warehouse_details)}\")\n",
    "print(f\"Occupied Slots: {len(items_per_slot)}\")\n",
    "print(f\"Empty Slots: {len(warehouse_details) - len(items_per_slot)}\")\n",
    "print(f\"Total Items Allocated: {items_per_slot['Item Count'].sum()}\")\n",
    "\n",
    "# Print the first few rows of each dataframe\n",
    "print(\"\\nWarehouse Details (first 5 rows):\")\n",
    "print(warehouse_details.head())\n",
    "\n",
    "print(\"\\nItems per Slot (first 5 rows):\")\n",
    "print(items_per_slot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdfce2-d89f-4222-a1d9-e674abd584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37079fed-3984-4340-bd81-8bc71fb2e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the mock inventory data\n",
    "df = pd.read_csv(\"mock_inventory_data_with_dimensions.csv\")\n",
    "\n",
    "# Assuming 'item_support' and 'sorted_frequent_itemsets' are defined earlier and contain the priority items identified using the FP Growth algorithm\n",
    "item_support = pd.read_csv(\"individual_item_frequencies.csv\")  # Placeholder, replace with actual loading mechanism\n",
    "sorted_frequent_itemsets = pd.read_csv(\"sorted_frequent_itemsets.csv\")  # Placeholder, replace with actual loading mechanism\n",
    "\n",
    "priority_items = set(item_support['itemsets'].apply(lambda x: list(eval(x))[0]))\n",
    "\n",
    "# Function to generate a warehouse with zones, racks, and slots\n",
    "def generate_warehouse(num_zones, required_capacity):\n",
    "    warehouse = {\"zones\": {}}\n",
    "    total_slots = 0\n",
    "    zone_num = 1\n",
    "    \n",
    "    while total_slots < required_capacity and zone_num <= num_zones:\n",
    "        zone_name = f\"Zone {zone_num}\"\n",
    "        warehouse[\"zones\"][zone_name] = {\"racks\": [], \"tags\": random.choice([\"Inflamable\", \"Chemical\", \"Grocery\", \"General\"])}\n",
    "        for rack_num in range(1, random.randint(2, 5) + 1):  # Random number of racks per zone\n",
    "            rack_name = f\"Rack {rack_num}\"\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"].append({\"rack_id\": rack_name, \"slots\": []})\n",
    "            for slot_num in range(1, random.randint(3, 6) + 1):  # Random number of slots per rack\n",
    "                slot_name = f\"Slot {slot_num}\"\n",
    "                warehouse[\"zones\"][zone_name][\"racks\"][-1][\"slots\"].append({\n",
    "                    \"slot_id\": slot_name,\n",
    "                    \"max_weight\": random.randint(300, 3000),  # Random max weight\n",
    "                    \"dimensions\": [\n",
    "                        random.randint(30, 80),  # Random dimensions\n",
    "                        random.randint(30, 80),\n",
    "                        random.randint(30, 80)\n",
    "                    ]\n",
    "                })\n",
    "                total_slots += 1\n",
    "\n",
    "            # Randomly assign near_picking_zone, near_packing_machine, and near_outbound_gate\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_picking_zone\"] = random.choice([True, False])\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_packing_machine\"] = random.choice([True, False])\n",
    "            warehouse[\"zones\"][zone_name][\"racks\"][-1][\"near_outbound_gate\"] = random.choice([True, False])\n",
    "        zone_num += 1\n",
    "\n",
    "    if total_slots < required_capacity:\n",
    "        print(\"Warning: Insufficient slots generated for the required capacity.\")\n",
    "    return warehouse\n",
    "\n",
    "# Function to find nearest slot based on item dimensions\n",
    "def find_nearest_slot(item, slots):\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(slots)\n",
    "    distances, indices = nbrs.kneighbors([item])\n",
    "    return indices[0][0]\n",
    "\n",
    "# Function to check if adding item exceeds rack weight limit\n",
    "def can_add_to_rack(current_weight, item_weight, max_weight):\n",
    "    return current_weight + item_weight <= max_weight\n",
    "\n",
    "# Function to assign items to racks and slots using knapsack algorithm\n",
    "def assign_items_to_slots(items, warehouse, sorted_frequent_itemsets):\n",
    "    assigned_slots = []\n",
    "    remaining_items = []\n",
    "\n",
    "    # Create a dictionary to store items that are frequently sold together\n",
    "    item_groups = {}\n",
    "    for _, row in sorted_frequent_itemsets.iterrows():\n",
    "        if len(row['itemsets']) > 1:\n",
    "            for item in row['itemsets']:\n",
    "                if item not in item_groups:\n",
    "                    item_groups[item] = set()\n",
    "                item_groups[item].update(row['itemsets'])\n",
    "\n",
    "    # Function to allocate items to slots\n",
    "    def allocate_items(item_list, zone_tags=None):\n",
    "        nonlocal current_weight, current_zone, current_rack\n",
    "        for _, item in item_list.iterrows():\n",
    "            item_name = item['ItemName']\n",
    "            item_dimensions = [item['Height(cm)'], item['Width(cm)'], item['Depth(cm)']]\n",
    "            item_weight = item['Weight(kg)']\n",
    "            item_category = item['Category']\n",
    "            item_tags = item['Tags']\n",
    "\n",
    "            if zone_tags and item_tags != zone_tags:\n",
    "                remaining_items.append(item)\n",
    "                continue\n",
    "\n",
    "            # Find suitable slots in the current rack\n",
    "            suitable_slots = []\n",
    "            for slot in current_rack['slots']:\n",
    "                if item_weight <= slot['max_weight'] and all([item_dimensions[i] <= slot['dimensions'][i] for i in range(3)]):\n",
    "                    suitable_slots.append((current_zone, current_rack['rack_id'], slot['slot_id'], slot['dimensions'], slot['max_weight'], current_rack['near_picking_zone'], current_rack['near_packing_machine'], current_rack['near_outbound_gate']))\n",
    "\n",
    "            # Find the nearest slot based on dimensions\n",
    "            if suitable_slots:\n",
    "                slot_dimensions = [s[3] for s in suitable_slots]\n",
    "                nearest_slot_index = find_nearest_slot(item_dimensions, slot_dimensions)\n",
    "\n",
    "                # Prioritize slots near picking zones for priority items\n",
    "                if item_name in priority_items:\n",
    "                    near_picking_slots = [i for i, s in enumerate(suitable_slots) if s[5]]  # s[5] is near_picking_zone\n",
    "                    if near_picking_slots:\n",
    "                        nearest_slot_index = near_picking_slots[0]\n",
    "\n",
    "                # Check if adding the item exceeds the rack's weight limit\n",
    "                if can_add_to_rack(current_weight, item_weight, suitable_slots[nearest_slot_index][4]):\n",
    "                    assigned_slots.append((item_name, suitable_slots[nearest_slot_index]))\n",
    "                    current_weight += item_weight\n",
    "\n",
    "                    # Try to allocate frequently sold together items\n",
    "                    if item_name in item_groups:\n",
    "                        for related_item in item_groups[item_name]:\n",
    "                            related_item_data = items[items['ItemName'] == related_item].iloc[0]\n",
    "                            if can_add_to_rack(current_weight, related_item_data['Weight(kg)'], suitable_slots[nearest_slot_index][4]):\n",
    "                                assigned_slots.append((related_item, suitable_slots[nearest_slot_index]))\n",
    "                                current_weight += related_item_data['Weight(kg)']\n",
    "                                items = items[items['ItemName'] != related_item]\n",
    "                else:\n",
    "                    remaining_items.append(item)\n",
    "            else:\n",
    "                remaining_items.append(item)\n",
    "\n",
    "    # Allocate special tagged items first\n",
    "    for zone, data in warehouse['zones'].items():\n",
    "        current_zone = zone\n",
    "        for rack in data['racks']:\n",
    "            current_rack = rack\n",
    "            current_weight = 0\n",
    "\n",
    "            special_tagged_items_df = items[items['Tags'] == data['tags']]\n",
    "            allocate_items(special_tagged_items_df, zone_tags=data['tags'])\n",
    "\n",
    "    # Allocate remaining items\n",
    "    for zone, data in warehouse['zones'].items():\n",
    "        current_zone = zone\n",
    "        for rack in data['racks']:\n",
    "            current_rack = rack\n",
    "            current_weight = 0\n",
    "\n",
    "            priority_items_df = items[items['ItemName'].isin(priority_items)]\n",
    "            non_priority_items_df = items[~items['ItemName'].isin(priority_items)]\n",
    "\n",
    "            allocate_items(priority_items_df)\n",
    "            allocate_items(non_priority_items_df)\n",
    "\n",
    "    return assigned_slots, remaining_items\n",
    "\n",
    "# Generate warehouse and check capacity\n",
    "warehouse = generate_warehouse(100, 100000)  # Increased number of zones to ensure capacity\n",
    "total_slots = sum(len(rack['slots']) for zone in warehouse['zones'].values() for rack in zone['racks'])\n",
    "print(f\"Total slots generated: {total_slots}\")\n",
    "\n",
    "# Assign items to slots\n",
    "assigned_slots, remaining_items = assign_items_to_slots(df, warehouse, sorted_frequent_itemsets)\n",
    "\n",
    "# Save assigned slots to CSV with priority and near picking zone labels\n",
    "assigned_slots_df = pd.DataFrame(assigned_slots, columns=['ItemName', 'Assigned Slot'])\n",
    "assigned_slots_df[['Zone', 'Rack', 'Slot', 'Slot Dimensions', 'Max Weight', 'Near Picking Zone', 'Near Packing Machine', 'Near Outbound Gate']] = pd.DataFrame(assigned_slots_df['Assigned Slot'].tolist(), index=assigned_slots_df.index)\n",
    "assigned_slots_df['Is Priority Item'] = assigned_slots_df['ItemName'].isin(priority_items)\n",
    "assigned_slots_df['Is Near Picking Zone'] = assigned_slots_df['Near Picking Zone']\n",
    "assigned_slots_df['Priority Near Picking'] = assigned_slots_df['Is Priority Item'] & assigned_slots_df['Is Near Picking Zone']\n",
    "assigned_slots_df['Special Tag'] = 'Priority'  # Adding a special tag for priority items\n",
    "assigned_slots_df.drop(columns=['Assigned Slot'], inplace=True)\n",
    "assigned_slots_df.to_csv('assigned_slots.csv', index=False)\n",
    "\n",
    "print(\"Assigned slots saved to 'assigned_slots.csv'.\")\n",
    "print(f\"Number of items successfully assigned: {len(assigned_slots)}\")\n",
    "print(f\"Number of items not assigned: {len(remaining_items)}\")\n",
    "\n",
    "def get_warehouse_details(warehouse):\n",
    "    details = []\n",
    "    for zone_name, zone_data in warehouse['zones'].items():\n",
    "        for rack in zone_data['racks']:\n",
    "            rack_id = rack['rack_id']\n",
    "            near_picking = rack['near_picking_zone']\n",
    "            near_packing = rack['near_packing_machine']\n",
    "            near_outbound = rack['near_outbound_gate']\n",
    "            for slot in rack['slots']:\n",
    "                details.append({\n",
    "                    'Zone': zone_name,\n",
    "                    'Zone Tags': zone_data['tags'],\n",
    "                    'Rack': rack_id,\n",
    "                    'Slot': slot['slot_id'],\n",
    "                    'Max Weight': slot['max_weight'],\n",
    "                    'Dimensions': slot['dimensions'],\n",
    "                    'Near Picking Zone': near_picking,\n",
    "                    'Near Packing Machine': near_packing,\n",
    "                    'Near Outbound Gate': near_outbound\n",
    "                })\n",
    "    return pd.DataFrame(details)\n",
    "\n",
    "def get_items_per_slot(assigned_slots_df):\n",
    "    items_per_slot = defaultdict(list)\n",
    "    for _, row in assigned_slots_df.iterrows():\n",
    "        slot_id = (row['Zone'], row['Rack'], row['Slot'])\n",
    "        items_per_slot[slot_id].append(row['ItemName'])\n",
    "    \n",
    "    slot_contents = []\n",
    "    for (zone, rack, slot), items in items_per_slot.items():\n",
    "        slot_contents.append({\n",
    "            'Zone': zone,\n",
    "            'Rack': rack,\n",
    "            'Slot': slot,\n",
    "            'Items': items\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(slot_contents)\n",
    "\n",
    "# Save warehouse details to CSV\n",
    "warehouse_details_df = get_warehouse_details(warehouse)\n",
    "warehouse_details_df.to_csv('warehouse_details.csv', index=False)\n",
    "print(\"Warehouse details saved to 'warehouse_details.csv'.\")\n",
    "\n",
    "# Save items per slot to CSV\n",
    "items_per_slot_df = get_items_per_slot(assigned_slots_df)\n",
    "items_per_slot_df.to_csv('items_per_slot.csv', index=False)\n",
    "print(\"Items per slot saved to 'items_per_slot.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd0652-6606-45a7-985e-28dabf61e717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
